{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Maja Kubara\"\n",
    "STUDENT_ID = \"14498863\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and data-linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pandas functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Basic Series Functionality\n",
    "Create a pandas `Series` with values `[1, 3, 5, np.nan, 6, 8]` and display basic functionality like `describe()`,` count()`, `sum()` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82fdeedf988907a74b17a01745454f7f",
     "grade": false,
     "grade_id": "cell-f561f052eef9823b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5.000000\n",
      "mean     4.600000\n",
      "std      2.701851\n",
      "min      1.000000\n",
      "25%      3.000000\n",
      "50%      5.000000\n",
      "75%      6.000000\n",
      "max      8.000000\n",
      "dtype: float64\n",
      "5\n",
      "23.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "#create a list with np.nan\n",
    "list_1 = [1,3,5,np.nan,6,8]\n",
    "#create series from list\n",
    "series_1 = pd.Series(list_1, copy=False).dropna()\n",
    "#print describe, count, and sum functions\n",
    "print(series_1.describe())\n",
    "print(series_1.count())\n",
    "print(series_1.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d8e2a8c10b241193b84a96ce4e29c85",
     "grade": true,
     "grade_id": "cell-33d19898476ae3ea",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 1\n",
    "assert series_1.sum() == 23, \"Check your series values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Series with Custom Index\n",
    "Create a `Series` with values `[30, 35, 40]` and indices `['Alice', 'Bob', 'Charlie']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e1dfa26d3f776267559933ec7bf04bf",
     "grade": false,
     "grade_id": "cell-5f1500ea9ce9c611",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice      30\n",
      "Bob        35\n",
      "Charlie    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "#create a dictionary\n",
    "dict_2 = {'Alice':30, 'Bob':35, 'Charlie':40}\n",
    "#create series from a dictionary\n",
    "series_2 = pd.Series(data=dict_2, index=['Alice', 'Bob', 'Charlie'])\n",
    "print(series_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b4b555dea6135aefc732106b18c654",
     "grade": true,
     "grade_id": "cell-9ac907bb27aa63c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 2\n",
    "assert 'Bob' in series_2, \"Ensure your series has the correct index.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Selection in Series\n",
    "Select and print the age of Bob from the `Series` created in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08281416ca8307af160aabb77068b54a",
     "grade": false,
     "grade_id": "cell-b320f5e1176aa070",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "#extract bob's age from the series_2\n",
    "age_bob = series_2['Bob']\n",
    "print(age_bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce42ef76e372c78094be619f1eeeda19",
     "grade": true,
     "grade_id": "cell-7a162b3d00a7c9dd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 3\n",
    "assert age_bob == 35, \"Check the value you extracted for Bob's age.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Filtering Condition\n",
    "Filter and display elements in `series_2` that are greater than 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af45a89f19be20e3dd0812d7f5244e01",
     "grade": false,
     "grade_id": "cell-db9ac814f6206b45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# filter series using loc, for number greater than 35\n",
    "filtered_series = series_2.loc[lambda x: x > 35]\n",
    "print(filtered_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7a697bef555d3b21027b1ef9a492242",
     "grade": true,
     "grade_id": "cell-e1b0f3aabc7c001d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4\n",
    "assert filtered_series['Charlie'] == 40, \"Check your filtering condition.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Creating a DataFrame\n",
    "Create a DataFrame using the dictionary below and assign it to a variable named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648e5c9e399f0e27526c3bc4092c45e7",
     "grade": false,
     "grade_id": "cell-6bf2866619f54dc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age     Name\n",
      "0   24    Alice\n",
      "1   27      Bob\n",
      "2   30  Charlie\n",
      "3   35    Diana\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary\n",
    "data = {\n",
    "    'Age': [24, 27, 30, 35],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana']\n",
    "}\n",
    "\n",
    "# Exercise 5\n",
    "# create a dataframe from dictionary\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f98439b06cec695e27322d3724d58e",
     "grade": true,
     "grade_id": "cell-1df22909ff854e72",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 5\n",
    "assert 'Name' in df, \"Ensure your DataFrame contains the correct columns.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Retrieving the Index or Columns\n",
    "Retrieve and print the index and columns of the `DataFrame` created in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e169e6f7cfbf540e5c9b82a587aa061",
     "grade": false,
     "grade_id": "cell-024f359d866c8a29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n",
      "Index(['Age', 'Name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "# save indexes and column names in variables\n",
    "index_df = df.index\n",
    "columns_df = df.columns\n",
    "# print variables\n",
    "print(index_df)\n",
    "print(columns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91b1c1cedbc1dccd8669d2d4f17f83e6",
     "grade": true,
     "grade_id": "cell-00da66dca230f648",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 6\n",
    "assert len(index_df) == 4 and len(columns_df) == 2, \"Check your index and columns extraction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Data Extraction with loc, iloc, and []\n",
    "Extract and print the `Age` of `Alice` using `loc`, `iloc`, and `[]` from the `DataFrame` created in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1557f6ed3b7a265d2cfd7d323687da1",
     "grade": false,
     "grade_id": "cell-ca64155f67b2dc58",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "# extract data using, loc, iloc and brackets []\n",
    "age_alice_loc = df.loc[0, 'Age']\n",
    "age_alice_iloc = df.iloc[0,0]\n",
    "age_alice_bracket = df['Age'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85c7c0018732a7123213c800843895ac",
     "grade": true,
     "grade_id": "cell-1d6147ef13c9d061",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 7\n",
    "assert age_alice_loc == 24 and age_alice_iloc == 24 and age_alice_bracket == 24, \"Check your data extraction methods.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Datasets\n",
    "\n",
    "Cool! Now that we have learned how pandas works, let's start using it with some data. \n",
    "\n",
    "### Exercise: Deterministic Data Linkage\n",
    "\n",
    "You will practice deterministic data linkage using synthetic datasets: `PatientDemo.csv` and `PatientVisits.csv`. Link these datasets using the `PatientID` field and perform analysis on the linked data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets as dataframes\n",
    "patient_df = pd.read_csv('PatientDemo.csv')\n",
    "visits_df = pd.read_csv('PatientVisits.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the data that we have to see if we can find how to link both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ac525bf90e585de37987d81ab26c2f9",
     "grade": false,
     "grade_id": "cell-e5338aee544ec758",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>1968-01-28</td>\n",
       "      <td>F</td>\n",
       "      <td>34536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>1942-02-11</td>\n",
       "      <td>F</td>\n",
       "      <td>73685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>1955-05-30</td>\n",
       "      <td>M</td>\n",
       "      <td>41751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1985-07-04</td>\n",
       "      <td>F</td>\n",
       "      <td>48590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>1948-07-01</td>\n",
       "      <td>F</td>\n",
       "      <td>74880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  FirstName LastName DateOfBirth Gender  ZipCode\n",
       "0          1      Megan    Mccoy  1968-01-28      F    34536\n",
       "1          2  Katherine    Bruce  1942-02-11      F    73685\n",
       "2          3     Robert  Sanchez  1955-05-30      M    41751\n",
       "3          4   Jonathan   Dennis  1985-07-04      F    48590\n",
       "4          5    William   Wilson  1948-07-01      F    74880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>VisitDate</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>TreatmentCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>D90</td>\n",
       "      <td>T36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>D29</td>\n",
       "      <td>T18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>D6</td>\n",
       "      <td>T31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>D74</td>\n",
       "      <td>T98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>D82</td>\n",
       "      <td>T62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitID  PatientID   VisitDate DiagnosisCode TreatmentCode\n",
       "0      101          1  2022-01-29           D90           T36\n",
       "1      102          2  2023-05-09           D29           T18\n",
       "2      103          3  2022-06-27            D6           T31\n",
       "3      104          4  2023-01-14           D74           T98\n",
       "4      105          5  2022-11-21           D82           T62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display dataframes\n",
    "display(patient_df.head())\n",
    "display(visits_df.head())\n",
    "\n",
    "# Count length of each dataframe, to see if the length is the same\n",
    "number_of_patients = len(patient_df.loc[:,'PatientID'])\n",
    "number_of_visits = len(visits_df.loc[:, 'PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be75019ed1533d01f9edfd48b7465181",
     "grade": true,
     "grade_id": "cell-e65882382c579a81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Print length\n",
    "print(number_of_patients)\n",
    "print(number_of_visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Linkage\n",
    "Perform deterministic data linkage by merging the `patient_df` and `visits_df` DataFrames using the `PatientID` field. Store the result in a new DataFrame called `merged_df`.\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17c028842e63e22a5b57609e2f6b3cf5",
     "grade": false,
     "grade_id": "cell-fac7892bca5e74e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>VisitID</th>\n",
       "      <th>VisitDate</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>TreatmentCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>1968-01-28</td>\n",
       "      <td>F</td>\n",
       "      <td>34536</td>\n",
       "      <td>101</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>D90</td>\n",
       "      <td>T36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>1942-02-11</td>\n",
       "      <td>F</td>\n",
       "      <td>73685</td>\n",
       "      <td>102</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>D29</td>\n",
       "      <td>T18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>1955-05-30</td>\n",
       "      <td>M</td>\n",
       "      <td>41751</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>D6</td>\n",
       "      <td>T31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1985-07-04</td>\n",
       "      <td>F</td>\n",
       "      <td>48590</td>\n",
       "      <td>104</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>D74</td>\n",
       "      <td>T98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>1948-07-01</td>\n",
       "      <td>F</td>\n",
       "      <td>74880</td>\n",
       "      <td>105</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>D82</td>\n",
       "      <td>T62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>Morales</td>\n",
       "      <td>1939-01-12</td>\n",
       "      <td>F</td>\n",
       "      <td>52118</td>\n",
       "      <td>196</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>D11</td>\n",
       "      <td>T13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Miles</td>\n",
       "      <td>1940-08-24</td>\n",
       "      <td>F</td>\n",
       "      <td>73439</td>\n",
       "      <td>197</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>D43</td>\n",
       "      <td>T61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Barnes</td>\n",
       "      <td>1940-07-14</td>\n",
       "      <td>M</td>\n",
       "      <td>68527</td>\n",
       "      <td>198</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>D95</td>\n",
       "      <td>T51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>Bates</td>\n",
       "      <td>1951-10-08</td>\n",
       "      <td>M</td>\n",
       "      <td>38488</td>\n",
       "      <td>199</td>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>D6</td>\n",
       "      <td>T81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Williams</td>\n",
       "      <td>1984-02-10</td>\n",
       "      <td>M</td>\n",
       "      <td>59292</td>\n",
       "      <td>200</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>D70</td>\n",
       "      <td>T11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID    FirstName  LastName DateOfBirth Gender  ZipCode  VisitID  \\\n",
       "0           1        Megan     Mccoy  1968-01-28      F    34536      101   \n",
       "1           2    Katherine     Bruce  1942-02-11      F    73685      102   \n",
       "2           3       Robert   Sanchez  1955-05-30      M    41751      103   \n",
       "3           4     Jonathan    Dennis  1985-07-04      F    48590      104   \n",
       "4           5      William    Wilson  1948-07-01      F    74880      105   \n",
       "..        ...          ...       ...         ...    ...      ...      ...   \n",
       "95         96      Sabrina   Morales  1939-01-12      F    52118      196   \n",
       "96         97        Laura     Miles  1940-08-24      F    73439      197   \n",
       "97         98  Christopher    Barnes  1940-07-14      M    68527      198   \n",
       "98         99        Chloe     Bates  1951-10-08      M    38488      199   \n",
       "99        100          Tom  Williams  1984-02-10      M    59292      200   \n",
       "\n",
       "     VisitDate DiagnosisCode TreatmentCode  \n",
       "0   2022-01-29           D90           T36  \n",
       "1   2023-05-09           D29           T18  \n",
       "2   2022-06-27            D6           T31  \n",
       "3   2023-01-14           D74           T98  \n",
       "4   2022-11-21           D82           T62  \n",
       "..         ...           ...           ...  \n",
       "95  2020-04-13           D11           T13  \n",
       "96  2023-05-27           D43           T61  \n",
       "97  2020-05-11           D95           T51  \n",
       "98  2022-03-13            D6           T81  \n",
       "99  2023-09-11           D70           T11  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.merge(patient_df, visits_df, on = 'PatientID')\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How many records are in the `merged_df` DataFrame?\n",
    "2. What is the average age of patients in `merged_df`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0540569141326e08acde1c919f0a4fe",
     "grade": false,
     "grade_id": "cell-ce9bb9e6c1a05c40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Question 1: How many records are in the merged_df DataFrame?\n",
    "\n",
    "# Use len function\n",
    "num_records = len(merged_df)\n",
    "\n",
    "# Question 2: What is the average age of patients in merged_df?\n",
    "\n",
    "# Hint: You can use the datetime module to get the current year.\n",
    "from datetime import datetime\n",
    "\n",
    "#Convert date to datetime format\n",
    "dateofbirth = pd.to_datetime(merged_df['DateOfBirth'])\n",
    "#Set current year\n",
    "current_year = datetime.now().year\n",
    "#Count age\n",
    "age = current_year - dateofbirth.dt.year\n",
    "#Count average\n",
    "average_age = age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11f2cd1f93b97b7c02c392a073f4329a",
     "grade": true,
     "grade_id": "cell-4cb0b75dd98cd98c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 records in the merged dataframe\n",
      "The avergae age of patients is 52.22\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {num_records} records in the merged dataframe')\n",
    "print(f'The avergae age of patients is {average_age}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Data Linkage\n",
    "\n",
    "Probabilistic data linkage is a technique used to bring together records from different datasets that do not share a unique identifier but have other fields in common. Unlike deterministic linkage, which requires exact matches on shared fields, probabilistic linkage considers the likelihood that two records refer to the same entity based on the similarity between these shared fields. This approach is particularly useful when working with data that may contain errors, variations, or inconsistencies in how information is recorded.\n",
    "\n",
    "## Challenges in Data Linkage\n",
    "\n",
    "- **Data Quality:** Datasets often have missing, misspelled, or inconsistently formatted data.\n",
    "- **Variability:** The same entity might be represented slightly differently in different datasets, due to typos, abbreviations, or variations in how data is entered.\n",
    "- **Absence of Unique Identifiers:** There might not be a unique, consistent identifier shared across datasets.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Probabilistic linkage typically involves the following steps:\n",
    "\n",
    "1. **Selecting Variables:** Choosing which fields (or combinations of fields) will be used to link records between datasets.\n",
    "2. **Measuring Similarity:** Calculating a similarity score between records based on the selected variables.\n",
    "3. **Setting Thresholds:** Determining a similarity threshold above which records will be considered a match.\n",
    "\n",
    "Various similarity or distance metrics can be used in step 2, depending on the nature of the data and the specific requirements of the linkage task. One such metric, designed to handle some of the challenges mentioned above, is the Jaro-Winkler Distance, which you have seen in the lecture about data linkage.\n",
    "\n",
    "\n",
    "## Understanding Jaro-Winkler Distance\n",
    "\n",
    "The Jaro-Winkler Distance (JWD) is a measure of similarity between two strings. It is a variant of the Jaro distance metric and is mainly used in the area of record linkage. The Jaro-Winkler Distance metric is designed to capture similarity between two strings while accounting for possible errors such as typos and characters out of place.\n",
    "\n",
    "**Mathematical Definition**\n",
    "\n",
    "The Jaro-Winkler Distance between two strings $ s1 $ and $ s2 $ is calculated as follows:\n",
    "\n",
    "1. **Jaro Distance Calculation:**\n",
    "    - Let $ m $ be the number of matching characters between the two strings.\n",
    "    - Let $ t $ be the number of transpositions between the two strings.\n",
    "    - The Jaro distance $ d_j $ is then given by the formula:\n",
    "    $$\n",
    "    d_j = \\frac{1}{3} \\left( \\frac{m}{|s1|} + \\frac{m}{|s2|} + \\frac{m-t}{m} \\right)\n",
    "    $$\n",
    "    where $ |s1| $ and $ |s2| $ are the lengths of the strings $ s1 $ and $ s2 $ respectively.\n",
    "\n",
    "2. **Jaro-Winkler Distance Calculation:**\n",
    "    - Let $ l $ be the length of common prefix at the start of the string (maximum 4 characters).\n",
    "    - The Jaro-Winkler distance $ d_{jw} $ is then given by the formula:\n",
    "    $$\n",
    "    d_{jw} = d_j + l p (1 - d_j)\n",
    "    $$\n",
    "    where $ p $ is a constant scaling factor (usually set to $ 0.1 $).\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "- The Jaro-Winkler Distance ranges from $ 0 $ to $ 1 $, where $ 0 $ represents completely dissimilar strings and $ 1 $ represents identical strings.\n",
    "- The distance is symmetric, meaning $ d_{jw}(s1, s2) = d_{jw}(s2, s1) $.\n",
    "- It is particularly useful for short strings and for applications where the strings being compared have small length variations, making it widely used in record linkage tasks.\n",
    "- The Jaro-Winkler adjustment gives more favorable ratings to strings that match from the beginning, making it useful for cases where the position of characters in the string is important.\n",
    "\n",
    "**Example**\n",
    "\n",
    "For instance, the strings \"MARTHA\" and \"MARHTA\" have a Jaro distance of approximately $ 0.944 $ and a Jaro-Winkler Distance of approximately $ 0.961 $ with a prefix length of $ 3 $ and scaling factor $ p = 0.1 $.\n",
    "\n",
    "\n",
    "## Exercise: Implement distance\n",
    "\n",
    "Complete the function below by implementing the Jaro-Winkler Distance Calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac67b3285f1347fbc5ae0f441ab40341",
     "grade": false,
     "grade_id": "cell-32fed749c259b2fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def jaro_winkler_distance(s1: str, s2: str) -> float:\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "\n",
    "    m = 0  # Number of matching characters\n",
    "    t = 0  # Number of transpositions\n",
    "    l = min(len(s1), len(s2))  # Length of the shorter string\n",
    "\n",
    "    # Compute the number of matching characters and transpositions\n",
    "    for i in range(l):\n",
    "        if s1[i] == s2[i]:\n",
    "            m += 1\n",
    "        elif s1[i] != s2[i] and (i == 0 or (i > 0 and s1[i - 1] == s2[i - 1])):\n",
    "            t += 1\n",
    "\n",
    "    # Compute the Jaro distance\n",
    "    jaro = (1/3) * ((m / len(s1)) + (m / len(s2)) + ((m - t / 2) / m)) if m != 0 else 0.0\n",
    "    \n",
    "    # Compute the Jaro-Winkler distance\n",
    "    p = 0.1  # Scaling factor (constant)\n",
    "    l = 0  # Length of common prefix at the start of the string (max 4)\n",
    "    for i in range(min(len(s1), len(s2), 4)):\n",
    "        if s1[i] == s2[i]:\n",
    "            l += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    jaro_winkler = jaro + ( 1 * p * (1 - jaro))\n",
    "    return jaro_winkler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b06286b9435241befa6102327ad995a9",
     "grade": true,
     "grade_id": "cell-3583a3edc1c47026",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert jaro_winkler_distance('12', '1') == 0.85, 'Check your implementation.'\n",
    "assert jaro_winkler_distance(\"SAME\", \"SAME\") == 1.0, \\\n",
    "    f'Expected 1.0 for identical strings, but got {jaro_winkler_distance(\"SAME\", \"SAME\")}'\n",
    "assert jaro_winkler_distance(\"\", \"NOTSAME\") == 0.0, \\\n",
    "    f'Expected 0.0 for empty string comparison, but got {jaro_winkler_distance(\"\", \"NOTSAME\")}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Introduction\n",
    "\n",
    "In this exercise, we will work with two synthetic datasets: `EmploymentData.csv` and `SocialNetworkData.csv`. These datasets represent a common scenario in data linkage projects where we have information about individuals spread across different sources.\n",
    "\n",
    "## EmploymentData.csv\n",
    "\n",
    "The `EmploymentData.csv` dataset contains information about employees in various companies. Each record provides details about an employee's first name (`EmployeeFirstName`), last name (`EmployeeLastName`), the company they work for (`Company`), their position (`Position`), and their employment start date (`StartDate`).\n",
    "\n",
    "Here's a preview of the `EmploymentData.csv` structure:\n",
    "\n",
    "| EmployeeFirstName | EmployeeLastName | Company  | Position                | StartDate  |\n",
    "|-------------------|------------------|----------|-------------------------|------------|\n",
    "| John              | Doe              | ABC Corp | Data Scientist          | 2022-01-15 |\n",
    "| ...               | ...              | ...      | ...                     | ...        |\n",
    "\n",
    "## SocialNetworkData.csv\n",
    "\n",
    "The `SocialNetworkData.csv` dataset represents profiles from a professional social network. Each record includes the first name (`FirstName`), last name (`LastName`), current job title (`CurrentJobTitle`), the number of connections (`ConnectionsCount`), and the profile creation date (`ProfileCreationDate`).\n",
    "\n",
    "Here's a preview of the `SocialNetworkData.csv` structure:\n",
    "\n",
    "| FirstName | LastName | CurrentJobTitle       | ConnectionsCount | ProfileCreationDate |\n",
    "|-----------|----------|-----------------------|------------------|---------------------|\n",
    "| Jon       | Does     | Senior Data Scientist | 300              | 2018-06-05          |\n",
    "| ...       | ...      | ...                   | ...              | ...                 |\n",
    "\n",
    "## Objective\n",
    "\n",
    "Your task is to link records between these datasets probabilistically, based on the similarity of names using the Jaro-Winkler distance measure you will implement. Due to potential variations in how names are represented in each dataset (e.g., nicknames, typos), the linkage process requires careful consideration and application of string similarity measures.\n",
    "\n",
    "Load the `EmploymentData.csv` and `SocialNetworkData.csv` datasets into two separate DataFrames: `employment_df` and `network_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the employment data\n",
    "employment_df = pd.read_csv('EmploymentData.csv')\n",
    "\n",
    "# Load the social network data\n",
    "network_df = pd.read_csv('SocialNetworkData.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Data Linkage\n",
    "Use the `jaro_winkler_distance` function you implemented to link records between the `employment_df` and `network_df` DataFrames with the highest average similarity and a threshold of above 0.40. Store the result in a new DataFrame called `linked_df`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b74c2ffad07a1e6dc4e909af646c368d",
     "grade": false,
     "grade_id": "cell-77d2d30109393775",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.65\n",
    "linked_records = []\n",
    "\n",
    "# Iterate through employment_df\n",
    "for idx1, row1 in employment_df.iterrows():\n",
    "    highest_similarity = 0\n",
    "    #best_match_index = -1\n",
    "    # Iterate through network_df\n",
    "    for idx2, row2 in network_df.iterrows():\n",
    "        # Calculate Jaro winkler distance for first names, last names and find average \n",
    "        first_name_similarity = jaro_winkler_distance(row1['EmployeeFirstName'], row2['FirstName'])\n",
    "        last_name_similarity = jaro_winkler_distance(row1['EmployeeLastName'], row2['LastName'])\n",
    "        average_similarity = (first_name_similarity + last_name_similarity) / 2\n",
    "        # Find the highest similarity\n",
    "        if average_similarity > highest_similarity:\n",
    "            data_row = row2\n",
    "            highest_similarity = average_similarity\n",
    "            #best_match_index = idx2\n",
    "            # Save name\n",
    "            name = row2['FirstName'] + ' ' + row2['LastName']\n",
    "    # Set threshold for similarity\n",
    "    if highest_similarity >= threshold:\n",
    "        name1 = row1['EmployeeFirstName'] + ' ' + row1['EmployeeLastName'] \n",
    "        name2 = name\n",
    "        # Append a list with tupils\n",
    "        linked_records.append((name1,name2,highest_similarity)) \n",
    "# Create a dataframe from a list\n",
    "records = pd.DataFrame(linked_records, columns = ['EmployeeName_1', 'EmployeeName_2', 'Similiarity'])\n",
    "# Merge name and last name together in the dataframes\n",
    "employment_df['EmployeeName_1'] = employment_df['EmployeeFirstName'] + ' ' + employment_df['EmployeeLastName']\n",
    "network_df['EmployeeName_2'] = network_df['FirstName'] + ' ' + network_df['LastName']\n",
    "# Merge all the dataframes together\n",
    "linked_df = pd.merge(employment_df, records, on = 'EmployeeName_1')\n",
    "linked_df = pd.merge(network_df, linked_df, on = 'EmployeeName_2')\n",
    "# Drop columns\n",
    "linked_df = linked_df.drop(columns = ['FirstName','LastName','EmployeeFirstName','EmployeeLastName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13480b04151fac7d7823a3f0df396ab8",
     "grade": true,
     "grade_id": "cell-d905cbbfeaa23aad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CurrentJobTitle</th>\n",
       "      <th>ConnectionsCount</th>\n",
       "      <th>ProfileCreationDate</th>\n",
       "      <th>EmployeeName_2</th>\n",
       "      <th>Company</th>\n",
       "      <th>Position</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EmployeeName_1</th>\n",
       "      <th>Similiarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisheries officer</td>\n",
       "      <td>278</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>Megan Mccoy</td>\n",
       "      <td>Brown-Miles</td>\n",
       "      <td>Product manager</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>Megan Mccoy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Development worker, community</td>\n",
       "      <td>82</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>Katherine Bruce</td>\n",
       "      <td>Rose-Freeman</td>\n",
       "      <td>Plant breeder/geneticist</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Katherine Bruce</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broadcast journalist</td>\n",
       "      <td>182</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>Rob Sanchez</td>\n",
       "      <td>Munoz, Smith and Williams</td>\n",
       "      <td>Pensions consultant</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>Robert Sanchez</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patent examiner</td>\n",
       "      <td>409</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>J. Dennis</td>\n",
       "      <td>Collins-Owens</td>\n",
       "      <td>Air traffic controller</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>Jonathan Dennis</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patent examiner</td>\n",
       "      <td>409</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>J. Dennis</td>\n",
       "      <td>Garcia Group</td>\n",
       "      <td>Housing manager/officer</td>\n",
       "      <td>2022-09-03</td>\n",
       "      <td>James Dennis</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Engineer, building services</td>\n",
       "      <td>483</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>Sabrina Morales</td>\n",
       "      <td>Hale, Fisher and Torres</td>\n",
       "      <td>Pensions consultant</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>Sabrina Morales</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Print production planner</td>\n",
       "      <td>433</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>Laura Miles</td>\n",
       "      <td>Thomas PLC</td>\n",
       "      <td>IT sales professional</td>\n",
       "      <td>2021-06-12</td>\n",
       "      <td>Laura Miles</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Engineer, energy</td>\n",
       "      <td>409</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>C. Barnes</td>\n",
       "      <td>Livingston-Walls</td>\n",
       "      <td>Prison officer</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>Christopher Barnes</td>\n",
       "      <td>0.713636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Theatre director</td>\n",
       "      <td>361</td>\n",
       "      <td>2023-07-09</td>\n",
       "      <td>Chloe Bates</td>\n",
       "      <td>Brown-Perry</td>\n",
       "      <td>Engineer, electronics</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>Chloe Bates</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Artist</td>\n",
       "      <td>385</td>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>Tom Williams</td>\n",
       "      <td>Navarro Inc</td>\n",
       "      <td>Meteorologist</td>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Tom Williams</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CurrentJobTitle  ConnectionsCount ProfileCreationDate  \\\n",
       "0               Fisheries officer               278          2022-01-25   \n",
       "1   Development worker, community                82          2019-01-18   \n",
       "2            Broadcast journalist               182          2020-10-03   \n",
       "3                 Patent examiner               409          2019-06-27   \n",
       "4                 Patent examiner               409          2019-06-27   \n",
       "..                            ...               ...                 ...   \n",
       "95    Engineer, building services               483          2022-07-07   \n",
       "96       Print production planner               433          2019-06-03   \n",
       "97               Engineer, energy               409          2022-05-25   \n",
       "98               Theatre director               361          2023-07-09   \n",
       "99                         Artist               385          2022-02-13   \n",
       "\n",
       "     EmployeeName_2                    Company                  Position  \\\n",
       "0       Megan Mccoy                Brown-Miles           Product manager   \n",
       "1   Katherine Bruce               Rose-Freeman  Plant breeder/geneticist   \n",
       "2       Rob Sanchez  Munoz, Smith and Williams       Pensions consultant   \n",
       "3         J. Dennis              Collins-Owens    Air traffic controller   \n",
       "4         J. Dennis               Garcia Group   Housing manager/officer   \n",
       "..              ...                        ...                       ...   \n",
       "95  Sabrina Morales    Hale, Fisher and Torres       Pensions consultant   \n",
       "96      Laura Miles                 Thomas PLC     IT sales professional   \n",
       "97        C. Barnes           Livingston-Walls            Prison officer   \n",
       "98      Chloe Bates                Brown-Perry     Engineer, electronics   \n",
       "99     Tom Williams                Navarro Inc             Meteorologist   \n",
       "\n",
       "     StartDate      EmployeeName_1  Similiarity  \n",
       "0   2021-03-31         Megan Mccoy     1.000000  \n",
       "1   2022-01-01     Katherine Bruce     1.000000  \n",
       "2   2020-05-21      Robert Sanchez     0.925000  \n",
       "3   2020-10-15     Jonathan Dennis     0.718750  \n",
       "4   2022-09-03        James Dennis     0.730000  \n",
       "..         ...                 ...          ...  \n",
       "95  2022-04-08     Sabrina Morales     1.000000  \n",
       "96  2021-06-12         Laura Miles     1.000000  \n",
       "97  2020-07-02  Christopher Barnes     0.713636  \n",
       "98  2022-04-03         Chloe Bates     1.000000  \n",
       "99  2023-08-28        Tom Williams     1.000000  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(linked_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Data Linkage Results\n",
    "\n",
    "After performing data linkage, it's crucial to evaluate the quality of our matches. This step helps identify potential errors and assess the effectiveness of our linkage technique.\n",
    "\n",
    "To quantify the quality, we'll focus on two key metrics:\n",
    "- **Precision**: Measures the correctness of the matches. A higher precision means fewer false positives.\n",
    "- **Recall**: Measures the completeness of the matches. A higher recall means fewer true matches were missed.\n",
    "\n",
    "Precision and recall are defined as:\n",
    "$$ \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Positives (FP)}} $$\n",
    "$$ \\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Negatives (FN)}} $$\n",
    "\n",
    "Using the ground truth (matches based on indices in this synthetic example), we can calculate these metrics to understand how well our linkage algorithm performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matches(employment_df, network_df):\n",
    "    # Ground truth matches based on indices\n",
    "    ground_truth = set([(idx, idx) for idx in employment_df.index if idx in network_df.index])\n",
    "\n",
    "    # Matches made by the linkage algorithm\n",
    "    predicted_matches = set([(idx1, idx2) for idx1, row1 in employment_df.iterrows() \n",
    "                            for idx2, row2 in network_df.iterrows() \n",
    "                            if (row1['EmployeeFirstName'], row1['EmployeeLastName']) == \n",
    "                                (row2['FirstName'], row2['LastName'])])\n",
    "\n",
    "    # True Positives: Ground truth matches that are in the predicted matches\n",
    "    TP = len(ground_truth.intersection(predicted_matches))\n",
    "\n",
    "    # False Positives: Predicted matches that are not in the ground truth\n",
    "    FP = len(predicted_matches.difference(ground_truth))\n",
    "\n",
    "    # False Negatives: Ground truth matches that are not in the predicted matches\n",
    "    FN = len(ground_truth.difference(predicted_matches))\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set threshold\n",
    "Now play around with the threshold and see how you could optimize the matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81bf63116e5be9bb354d0233e65743cc",
     "grade": false,
     "grade_id": "cell-9098da9f7c3003d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.73)\n"
     ]
    }
   ],
   "source": [
    "matches = evaluate_matches(employment_df, network_df)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60daf24dee8569bdd625fb74a382b1c3",
     "grade": false,
     "grade_id": "cell-d5a79e1c0a1d2d61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conceptual Exercise: Data Linkage with Different Measurement Scales\n",
    "\n",
    "### Background\n",
    "Imagine you are working with two datasets collected from two different social surveys conducted in a city:\n",
    "\n",
    "1. **CityResidentSurvey.csv:**\n",
    "   - **Age:** Age of the resident.\n",
    "   - **Income:** Monthly income of the resident in USD.\n",
    "   - **EducationLevel:** Highest level of education attained (coded as 1: High School, 2: Bachelor’s, 3: Master’s, 4: Doctorate).\n",
    "   - **ResidentID:** A unique identifier for each resident in the survey.\n",
    "\n",
    "2. **NeighborhoodWellbeingSurvey.csv:**\n",
    "   - **Resident_Age:** Age of the resident, but with a ±2 years error margin due to the way it was collected.\n",
    "   - **Annual_Income:** Yearly income of the resident in USD.\n",
    "   - **Edu_Level:** Highest level of education attained, described with words (High School, Bachelor's Degree, Master's Degree, Doctorate).\n",
    "   - **WellbeingIndex:** A score representing the resident’s perceived wellbeing.\n",
    "   - **Resident_ID:** A unique identifier, but it does not match the ResidentID in the CityResidentSurvey.\n",
    "\n",
    "### Task\n",
    "You are tasked to link records between these two datasets. However, the data points are not measured exactly the same way in both datasets. Specifically:\n",
    "- Age is measured with a ±2 years error in the second dataset.\n",
    "- Income is reported monthly in the first dataset and annually in the second.\n",
    "- Education levels are coded numerically in the first dataset and described with words in the second.\n",
    "\n",
    "### Question\n",
    "Describe a step-by-step approach to link records between the two datasets as accurately as possible. Consider the differences in the measurement scales and potential errors in the data. How would you account for these differences to improve the accuracy of your linkage? You don't have to write any code, just explain your approach conceptually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa6a13db09f5c3003bb9745eac780117",
     "grade": true,
     "grade_id": "cell-8ba6fc8b8431eecc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer: \n",
    "1. I would estimate annual income in City resident survey\n",
    "2. I would standarise the way the education level is described, change in neighbourhood wellbeing   survey education level to numbers as it is in city resident survey\n",
    "3. Based on annual income and education level I would match the datasets\n",
    "4. Then I would check if the age of the residents matches with an error of 2 years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
